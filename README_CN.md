# ç¾Šç¾¤å¼•å¯¼é«˜å±‚å†³ç­–æ§åˆ¶å™¨ (ç®€åŒ–ç‰ˆ)

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12%2B-orange.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

**åŸºäºå•æ™ºèƒ½ä½“PPOç®—æ³•çš„ç¾Šç¾¤å¼•å¯¼æ§åˆ¶ç³»ç»Ÿ**

[é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹) â€¢ [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§) â€¢ [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) â€¢ [ç®—æ³•åŸç†](#ç®—æ³•åŸç†)

</div>

---

## ç›®å½•

- [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)
- [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
- [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
- [ç¯å¢ƒè¦æ±‚](#ç¯å¢ƒè¦æ±‚)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [ç®—æ³•åŸç†](#ç®—æ³•åŸç†)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [å¯è§†åŒ–å·¥å…·](#å¯è§†åŒ–å·¥å…·)
- [ä¸MAPPOç‰ˆæœ¬å¯¹æ¯”](#ä¸mappoç‰ˆæœ¬å¯¹æ¯”)
- [è®¸å¯è¯](#è®¸å¯è¯)

---

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ª**åŸºäºå•æ™ºèƒ½ä½“PPOï¼ˆProximal Policy Optimizationï¼‰ç®—æ³•çš„é«˜å±‚å†³ç­–æ§åˆ¶å™¨**ï¼Œç”¨äºå¤šæœºå™¨äººç¾Šç¾¤å¼•å¯¼ä»»åŠ¡ã€‚æ§åˆ¶å™¨é€šè¿‡å®æ—¶åˆ†æç¾Šç¾¤çŠ¶æ€ä¿¡æ¯ï¼Œè¾“å‡ºå½’ä¸€åŒ–çš„ç«™ä½å‚æ•°ï¼Œç»è¿‡è§£ç å™¨è½¬æ¢ä¸ºæœºæ¢°ç‹—çš„ç›®æ ‡ä½ç½®ï¼Œå®ç°é«˜æ•ˆçš„ç¾Šç¾¤å¼•å¯¼ã€‚

### è®¾è®¡ç†å¿µ

æœ¬é¡¹ç›®æ˜¯ç¾Šç¾¤å¼•å¯¼ç³»ç»Ÿçš„**ç®€åŒ–ç‰ˆæœ¬**ï¼Œä¸“æ³¨äºï¼š

- ğŸ¯ **ç®€å•é«˜æ•ˆ**ï¼šå•æ™ºèƒ½ä½“PPOï¼Œæ˜“äºè®­ç»ƒå’Œè°ƒè¯•
- ğŸ“ **å½’ä¸€åŒ–åŠ¨ä½œç©ºé—´**ï¼šæ‰€æœ‰åŠ¨ä½œåœ¨[-1, 1]èŒƒå›´å†…ï¼Œæå‡æ¢ç´¢æ•ˆç‡
- ğŸ”„ **é«˜å±‚åŠ¨ä½œè§£ç **ï¼šç›´è§‚çš„ç¼–é˜Ÿæ§åˆ¶è¯­ä¹‰
- ğŸ“Š **å¢å¼ºå¥–åŠ±å‡½æ•°**ï¼šå¯†é›†ã€å¹³æ»‘çš„åé¦ˆä¿¡å·
- ğŸ§­ **ç›¸å¯¹åŒ–è§‚æµ‹**ï¼šæ›´é€‚åˆç­–ç•¥å­¦ä¹ çš„è§‚æµ‹è¡¨ç¤º

### åº”ç”¨åœºæ™¯

- ğŸ‘ **æ™ºèƒ½ç•œç‰§**ï¼šè‡ªåŠ¨åŒ–ç¾Šç¾¤ç®¡ç†ä¸å¼•å¯¼
- ğŸ¤– **å¤šæœºå™¨äººååŒ**ï¼šåˆ†å±‚æ§åˆ¶æ¶æ„ç ”ç©¶
- ğŸ® **å¼ºåŒ–å­¦ä¹ ç ”ç©¶**ï¼šå•æ™ºèƒ½ä½“RLç®—æ³•éªŒè¯å¹³å°
- ğŸ­ **åŸå‹å¼€å‘**ï¼šå¿«é€ŸéªŒè¯ç¾Šç¾¤å¼•å¯¼ç­–ç•¥

---

## æ ¸å¿ƒç‰¹æ€§

### åŠŸèƒ½ç‰¹æ€§

| ç‰¹æ€§ | æè¿° |
|------|------|
| **å½’ä¸€åŒ–åŠ¨ä½œç©ºé—´** | 4ç»´è¿ç»­åŠ¨ä½œï¼ŒèŒƒå›´ç»Ÿä¸€ä¸º[-1, 1] |
| **é«˜å±‚åŠ¨ä½œè§£ç å™¨** | å°†å½’ä¸€åŒ–åŠ¨ä½œè½¬æ¢ä¸ºç‰©ç†ç«™ä½å‚æ•° |
| **ç›¸å¯¹åŒ–è§‚æµ‹** | 10ç»´ç›¸å¯¹åŒ–è§‚æµ‹å‘é‡ï¼Œæ›´åˆ©äºç­–ç•¥å­¦ä¹  |
| **å¢å¼ºå¥–åŠ±å‡½æ•°** | 5ä¸ªå¥–åŠ±ç»„ä»¶ï¼Œæä¾›å¯†é›†å¹³æ»‘çš„åé¦ˆ |
| **ç‰©ç†çº¦æŸç§»åŠ¨** | æœºæ¢°ç‹—ä½¿ç”¨åŠ¿åœºæ³•å¹³æ»‘ç§»åŠ¨ |
| **æ”¹è¿›çš„ç¾Šç¾¤è¡Œä¸º** | å¹³æ»‘çš„é€ƒé¿åŠ›è®¡ç®—ï¼Œé¿å…åŠ›çˆ†ç‚¸ |
| **å¯è§†åŒ–å·¥å…·** | å®æ—¶æ¸²æŸ“è®­ç»ƒè¿‡ç¨‹å’Œç­–ç•¥è¡¨ç° |

### æ€§èƒ½ç‰¹ç‚¹

| ç‰¹ç‚¹ | è¯´æ˜ |
|------|------|
| **è®­ç»ƒæ•ˆç‡** | å•æ™ºèƒ½ä½“ï¼Œæ”¶æ•›æ›´å¿« |
| **æ¢ç´¢æ•ˆç‡** | å½’ä¸€åŒ–åŠ¨ä½œç©ºé—´ï¼Œæ¢ç´¢æ›´å‡åŒ€ |
| **ç­–ç•¥æ³›åŒ–** | ç›¸å¯¹åŒ–è§‚æµ‹ï¼Œå¯¹åœºæ™¯å˜åŒ–æ›´é²æ£’ |
| **è°ƒè¯•å‹å¥½** | ç®€åŒ–çš„æ¶æ„ï¼Œæ˜“äºåˆ†æå’Œè°ƒè¯• |

---

## ç³»ç»Ÿæ¶æ„

### åˆ†å±‚æ§åˆ¶æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              é«˜å±‚æ§åˆ¶å™¨ (æœ¬é¡¹ç›®)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ç¾Šç¾¤çŠ¶æ€æ„ŸçŸ¥ â†’ PPOç­–ç•¥ â†’ å½’ä¸€åŒ–åŠ¨ä½œè¾“å‡º     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  é«˜å±‚åŠ¨ä½œè§£ç å™¨ (HighLevelAction)            â”‚   â”‚
â”‚  â”‚  [-1,1] â†’ æ¥”å½¢ä¸­å¿ƒ/å®½åº¦/åŠå¾„/ä¸å¯¹ç§°åº¦        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ ç«™ä½å‚æ•°
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ä½å±‚æ§åˆ¶å™¨ (å¤–éƒ¨ç³»ç»Ÿ)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  è¿åŠ¨æ§åˆ¶ â”‚ è½¨è¿¹è·Ÿè¸ª â”‚ é¿éšœæ§åˆ¶              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒæ¨¡å—

1. **ç¯å¢ƒæ¨¡å— (envs/)**
   - `sheep_entity.py`ï¼šç¾Šç¾¤å®ä½“ç±»ï¼Œå®ç°Boidsæ¨¡å‹
   - `sheep_scenario.py`ï¼šåœºæ™¯ç®¡ç†ï¼ŒçŠ¶æ€è®¡ç®—
   - `sheep_flock.py`ï¼šGymé£æ ¼ç¯å¢ƒå°è£…
   - `high_level_action.py`ï¼šé«˜å±‚åŠ¨ä½œè§£ç å™¨ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰

2. **ç®—æ³•æ¨¡å— (onpolicy/)**
   - `ppo_actor_critic.py`ï¼šActor-Criticç½‘ç»œ
   - `ppo_buffer.py`ï¼šç»éªŒå›æ”¾ç¼“å†²
   - `mlp.py`ã€`rnn.py`ï¼šç½‘ç»œç»„ä»¶

3. **è®­ç»ƒæ¨¡å—**
   - `train_ppo.py`ï¼šè®­ç»ƒå…¥å£è„šæœ¬

4. **å¯è§†åŒ–æ¨¡å—**
   - `visualize.py`ï¼šæ¨¡å‹å¯è§†åŒ–è¿è¡Œè„šæœ¬

---

## ç¯å¢ƒè¦æ±‚

### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**ï¼šLinux (Ubuntu 18.04+) / macOS / Windows 10+
- **Pythonç‰ˆæœ¬**ï¼š3.8 æˆ–æ›´é«˜
- **å†…å­˜**ï¼šâ‰¥ 4GB RAM
- **GPU**ï¼šå¯é€‰ï¼Œæ¨èNVIDIA GPU (CUDA 10.2+)

### æ ¸å¿ƒä¾èµ–

```
numpy>=1.21.0,<2.0.0
torch>=1.12.0,<3.0.0
gym>=0.21.0,<1.0.0
matplotlib>=3.5.0,<4.0.0
scipy>=1.7.0,<2.0.0
```

---

## å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/your-username/high_layer.git
cd high_layer
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
conda create -n ppo_sheep python=3.8
conda activate ppo_sheep
```

### 3. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 4. è¿è¡Œè®­ç»ƒ

```bash
python train_ppo.py --num_sheep 10 --num_herders 3 --episode_length 150
```

### 5. å¯è§†åŒ–è®­ç»ƒç»“æœ

```bash
python visualize.py --model_path results/models/model_xxx.pt --num_episodes 5
```

---

## é¡¹ç›®ç»“æ„

```
high_layer/
â”œâ”€â”€ envs/                          # ç¯å¢ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sheep_entity.py            # ç¾Šç¾¤å®ä½“ç±» (Boidsæ¨¡å‹)
â”‚   â”œâ”€â”€ sheep_scenario.py          # åœºæ™¯ç®¡ç†ç±»
â”‚   â”œâ”€â”€ sheep_flock.py             # ç¾Šç¾¤ç¯å¢ƒç±» (Gymæ¥å£)
â”‚   â””â”€â”€ high_level_action.py       # é«˜å±‚åŠ¨ä½œè§£ç å™¨ (æ ¸å¿ƒ)
â”œâ”€â”€ onpolicy/                      # ç®—æ³•æ¨¡å—
â”‚   â”œâ”€â”€ algorithms/
â”‚   â”‚   â”œâ”€â”€ ppo_actor_critic.py    # PPO Actor-Criticç½‘ç»œ
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ mlp.py             # MLPç½‘ç»œ
â”‚   â”‚       â”œâ”€â”€ rnn.py             # RNNç½‘ç»œ
â”‚   â”‚       â”œâ”€â”€ bounded_act.py     # æœ‰ç•ŒåŠ¨ä½œå±‚
â”‚   â”‚       â””â”€â”€ util.py            # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ ppo_buffer.py          # PPOç»éªŒç¼“å†²
â”‚       â””â”€â”€ util.py                # å·¥å…·å‡½æ•°
â”œâ”€â”€ results/                       # è®­ç»ƒç»“æœ (è‡ªåŠ¨ç”Ÿæˆ)
â”œâ”€â”€ train_ppo.py                   # è®­ç»ƒå…¥å£
â”œâ”€â”€ visualize.py                   # å¯è§†åŒ–è„šæœ¬
â”œâ”€â”€ requirements.txt               # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README_CN.md                   # é¡¹ç›®è¯´æ˜
```

---

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬è®­ç»ƒ

```bash
python train_ppo.py \
    --num_sheep 10 \
    --num_herders 3 \
    --episode_length 150 \
    --num_env_steps 1000000 \
    --lr 3e-4 \
    --seed 1
```

### å…³é”®å‚æ•°è¯´æ˜

#### ç¯å¢ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--num_sheep` | 10 | ç¾Šç¾¤æ•°é‡ |
| `--num_herders` | 3 | æœºæ¢°ç‹—æ•°é‡ |
| `--episode_length` | 150 | æ¯ä¸ªepisodeçš„æ­¥æ•° |
| `--world_size` | [50.0, 50.0] | ä¸–ç•Œå¤§å° |

#### è®­ç»ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--num_env_steps` | 1000000 | æ€»è®­ç»ƒæ­¥æ•° |
| `--lr` | 3e-4 | å­¦ä¹ ç‡ |
| `--ppo_epoch` | 10 | PPOæ›´æ–°è½®æ•° |
| `--num_mini_batch` | 4 | mini-batchæ•°é‡ |
| `--clip_param` | 0.2 | PPOè£å‰ªå‚æ•° |
| `--gamma` | 0.99 | æŠ˜æ‰£å› å­ |
| `--gae_lambda` | 0.95 | GAEå‚æ•° |

#### ç½‘ç»œå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--hidden_size` | 64 | éšè—å±‚å¤§å° |
| `--layer_N` | 3 | ç½‘ç»œå±‚æ•° |
| `--use_ReLU` | True | ä½¿ç”¨ReLUæ¿€æ´» |

### å¯è§†åŒ–è¿è¡Œ

```bash
python visualize.py \
    --model_path results/sheep_herding/default/ppo/seed1/models/model_100000.pt \
    --num_episodes 5 \
    --render_delay 30
```

#### å¯è§†åŒ–å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--model_path` | å¿…éœ€ | æ¨¡å‹æ–‡ä»¶è·¯å¾„ |
| `--num_episodes` | 5 | è¿è¡Œepisodeæ•°é‡ |
| `--render_delay` | 30 | æ¸²æŸ“å»¶è¿Ÿ(ms) |
| `--save_gif` | None | ä¿å­˜GIFè·¯å¾„ |
| `--save_video` | None | ä¿å­˜è§†é¢‘è·¯å¾„ |

---

## ç®—æ³•åŸç†

### PPOç®—æ³•

PPOï¼ˆProximal Policy Optimizationï¼‰æ˜¯ä¸€ç§ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œé€šè¿‡é™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦æ¥ä¿è¯è®­ç»ƒç¨³å®šæ€§ï¼š

#### æ ¸å¿ƒå…¬å¼

**ç­–ç•¥æŸå¤±**ï¼š
```
L^{CLIP} = E[min(r_t(Î¸)A_t, clip(r_t(Î¸), 1-Îµ, 1+Îµ)A_t)]
```

**ä»·å€¼æŸå¤±**ï¼š
```
L^{VF} = E[(V(s_t) - R_t)^2]
```

**æ€»æŸå¤±**ï¼š
```
L = L^{CLIP} - c_1 L^{VF} + c_2 S[Ï€](s)
```

### è§‚æµ‹ç©ºé—´è®¾è®¡

è§‚æµ‹å‘é‡ä¸º**10ç»´ç›¸å¯¹åŒ–è¡¨ç¤º**ï¼š

| ç»´åº¦ | å†…å®¹ | è¯´æ˜ |
|------|------|------|
| [0] | d_goal / r_max | åˆ°ç›®æ ‡è·ç¦»å½’ä¸€åŒ– |
| [1:3] | cos Ï†, sin Ï† | åˆ°ç›®æ ‡æ–¹å‘å•ä½å‘é‡ |
| [3] | flock_speed / max_speed | ç¾Šç¾¤é€Ÿåº¦å½’ä¸€åŒ– |
| [4:6] | cos Î¸_vel, sin Î¸_vel | é€Ÿåº¦æ–¹å‘(ç›¸å¯¹ç›®æ ‡) |
| [6] | spread / r_max | ç¾Šç¾¤æ‰©æ•£åº¦å½’ä¸€åŒ– |
| [7:9] | cos Î¸_main, sin Î¸_main | ç¾Šç¾¤ä¸»æ–¹å‘(ç›¸å¯¹ç›®æ ‡) |
| [9] | num_sheep / 30.0 | ç¾Šç¾¤æ•°é‡å½’ä¸€åŒ– |

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- ä½¿ç”¨ä¸‰è§’å‡½æ•°è¡¨ç¤ºè§’åº¦ï¼Œé¿å…å‘¨æœŸæ€§é—®é¢˜
- ç›¸å¯¹åŒ–è¡¨ç¤ºæé«˜ç­–ç•¥æ³›åŒ–èƒ½åŠ›
- å½’ä¸€åŒ–æ•°å€¼èŒƒå›´ï¼ŒåŠ é€Ÿè®­ç»ƒæ”¶æ•›

### åŠ¨ä½œç©ºé—´è®¾è®¡

åŠ¨ä½œå‘é‡ä¸º**4ç»´å½’ä¸€åŒ–è¿ç»­å€¼**ï¼ŒèŒƒå›´[-1, 1]ï¼š

| ç»´åº¦ | å†…å®¹ | è§£ç åå«ä¹‰ |
|------|------|-----------|
| [0] | wedge_center | æ¥”å½¢ä¸­å¿ƒè§’åº¦åç§» |
| [1] | wedge_width | ç«™ä½å±•å¼€å®½åº¦ (0=é›†ä¸­æ¨, 1=åŒ…å›´) |
| [2] | radius | ç«™ä½åŠå¾„ |
| [3] | asymmetry | ä¸å¯¹ç§°åç§» (ç”¨äºè½¬å‘) |

### é«˜å±‚åŠ¨ä½œè§£ç å™¨

`HighLevelAction` ç±»å°†å½’ä¸€åŒ–åŠ¨ä½œè½¬æ¢ä¸ºç‰©ç†å‚æ•°ï¼š

```python
class HighLevelAction:
    def decode_action(self, raw_action, target_direction):
        # è§£ç å½’ä¸€åŒ–åŠ¨ä½œ
        wedge_center = target_direction + raw_action[0] * np.pi
        wedge_width = (raw_action[1] + 1) / 2  # [0, 1]
        radius = R_min + (raw_action[2] + 1) / 2 * (R_max - R_min)
        asymmetry = raw_action[3] * 0.5
        ...
```

**ç¼–é˜Ÿæ¨¡å¼**ï¼š
- `PUSH` (wedge_width < 0.2)ï¼šé›†ä¸­æ¨æŒ¤
- `NARROW` (0.2 â‰¤ wedge_width < 0.5)ï¼šçª„è§’ç«™ä½
- `WIDE` (0.5 â‰¤ wedge_width < 0.8)ï¼šå®½è§’ç«™ä½
- `SURROUND` (wedge_width â‰¥ 0.8)ï¼š360Â°åŒ…å›´

### å¥–åŠ±å‡½æ•°è®¾è®¡

å¥–åŠ±å‡½æ•°åŒ…å«**5ä¸ªç»„ä»¶**ï¼Œæä¾›å¯†é›†å¹³æ»‘çš„åé¦ˆï¼š

```python
reward = (
    distance_reward +      # è·ç¦»å¥–åŠ± (æ ¸å¿ƒä¿¡å·)
    progress_reward +      # è¿›åº¦å¥–åŠ± (å¡‘å½¢ä¿¡å·)
    spread_reward +        # èšé›†åº¦å¥–åŠ± (ä¸­é—´ä¿¡å·)
    position_quality +     # ç«™ä½è´¨é‡å¥–åŠ± (ä¸­é—´ä¿¡å·)
    success_bonus          # æˆåŠŸå¥–åŠ± (ç¨€ç–ä¿¡å·)
)
```

| ç»„ä»¶ | å…¬å¼ | æƒé‡ |
|------|------|------|
| è·ç¦»å¥–åŠ± | exp(-3.0 * distance_ratio) | 1.0 |
| è¿›åº¦å¥–åŠ± | tanh(progress_ratio) * 0.5 | 0.5 |
| èšé›†åº¦å¥–åŠ± | exp(-spread / 5.0) * 0.3 | 0.3 |
| ç«™ä½è´¨é‡ | exp(-\|distance - 8.0\| / 3.0) * 0.2 | 0.2 |
| æˆåŠŸå¥–åŠ± | 2.0 + å¿«é€ŸæˆåŠŸ0.5 | 2.0-2.5 |

---

## é…ç½®è¯´æ˜

### ç¯å¢ƒé…ç½®

```python
from envs import SheepFlockEnv

env = SheepFlockEnv(
    world_size=(50.0, 50.0),      # ä¸–ç•Œå¤§å°
    num_sheep=10,                  # ç¾Šç¾¤æ•°é‡
    num_herders=3,                 # æœºæ¢°ç‹—æ•°é‡
    episode_length=150,            # episodeé•¿åº¦
    dt=0.1,                        # æ—¶é—´æ­¥é•¿
    reward_config={                # å¥–åŠ±é…ç½®
        'distance_reward_weight': 1.0,
        'spread_penalty_weight': 0.1,
        'success_bonus': 10.0,
    }
)
```

### ç¾Šç¾¤è¡Œä¸ºé…ç½®

```python
sheep_config = {
    'max_speed': 3.0,              # æœ€å¤§é€Ÿåº¦
    'max_force': 0.3,              # æœ€å¤§è½¬å‘åŠ›
    'perception_radius': 5.0,      # æ„ŸçŸ¥åŠå¾„
    'separation_radius': 2.0,      # åˆ†ç¦»åŠå¾„
}

boids_weights = {
    'separation': 1.5,             # åˆ†ç¦»æƒé‡
    'alignment': 1.0,              # å¯¹é½æƒé‡
    'cohesion': 1.0,               # èšåˆæƒé‡
    'evasion': 2.0,                # é€ƒé¿æƒé‡
    'boundary': 1.0,               # è¾¹ç•Œæƒé‡
}
```

---

## å¯è§†åŒ–å·¥å…·

### è¿è¡Œå¯è§†åŒ–

```bash
python visualize.py --model_path path/to/model.pt
```

### å¯è§†åŒ–ç•Œé¢è¯´æ˜

å¯è§†åŒ–ç•Œé¢æ˜¾ç¤ºä»¥ä¸‹å…ƒç´ ï¼š

| å…ƒç´  | é¢œè‰² | è¯´æ˜ |
|------|------|------|
| ç»¿è‰²æ˜Ÿå½¢ | ç»¿è‰² | ç›®æ ‡ä½ç½® |
| ç°è‰²åœ†å½¢ | ç°è‰² | ç¾Šç¾¤ |
| è“è‰²æ–¹å½¢ | è“è‰² | æœºæ¢°ç‹—å½“å‰ä½ç½® |
| æ©™è‰²åœ†ç¯ | æ©™è‰² | ç«™ä½åŠå¾„ |
| çº¢è‰²åœ†å½¢ | çº¢è‰² | ä¸»ç«™ä½ç›®æ ‡ |
| æ©™è‰²æ‰‡å½¢ | æ©™è‰² | ç«™ä½åŒºåŸŸ |
| è“è‰²è™šçº¿åœ† | è“è‰² | æœºæ¢°ç‹—å½±å“èŒƒå›´ |

### äº¤äº’æ§åˆ¶

- **ç©ºæ ¼é”®**ï¼šæš‚åœ/ç»§ç»­
- **PauseæŒ‰é’®**ï¼šæš‚åœ/ç»§ç»­

### ä¿å­˜åŠ¨ç”»

```bash
# ä¿å­˜GIF
python visualize.py --model_path model.pt --save_gif animation.gif

# ä¿å­˜è§†é¢‘
python visualize.py --model_path model.pt --save_video animation.mp4
```

---

## ä¸MAPPOç‰ˆæœ¬å¯¹æ¯”

æœ¬é¡¹ç›® (`high_layer`) ä¸ `mappo_layered_shepherd` çš„ä¸»è¦åŒºåˆ«ï¼š

| ç‰¹æ€§ | high_layer (æœ¬é¡¹ç›®) | mappo_layered_shepherd |
|------|---------------------|------------------------|
| **ç®—æ³•** | å•æ™ºèƒ½ä½“PPO | å¤šæ™ºèƒ½ä½“MAPPO |
| **åŠ¨ä½œç©ºé—´** | å½’ä¸€åŒ–[-1, 1] | ç‰©ç†å‚æ•° |
| **è§‚æµ‹ç©ºé—´** | ç›¸å¯¹åŒ–è¡¨ç¤º | ç»å¯¹åæ ‡ |
| **å¥–åŠ±å‡½æ•°** | 5ç»„ä»¶å¢å¼º | 3ç»„ä»¶åŸºç¡€ |
| **æœºæ¢°ç‹—ç§»åŠ¨** | åŠ¿åœºæ³•å¹³æ»‘ç§»åŠ¨ | ç›´æ¥è®¾ç½®ä½ç½® |
| **ç¾Šç¾¤é€ƒé¿** | çº¿æ€§è¡°å‡åŠ› | åå¹³æ–¹åŠ› |
| **è§£ç å™¨** | é«˜å±‚åŠ¨ä½œè§£ç å™¨ | æ—  |
| **å¤æ‚åº¦** | ç®€å• | å®Œæ•´ |

### é€‚ç”¨åœºæ™¯

- **é€‰æ‹©æœ¬é¡¹ç›®**ï¼šå¿«é€ŸåŸå‹éªŒè¯ã€ç®—æ³•è°ƒè¯•ã€æ•™å­¦æ¼”ç¤º
- **é€‰æ‹©MAPPOç‰ˆæœ¬**ï¼šå®Œæ•´å¤šæ™ºèƒ½ä½“è®­ç»ƒã€å­¦æœ¯ç ”ç©¶ã€ç”Ÿäº§éƒ¨ç½²

---

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

---

## è‡´è°¢

### å‚è€ƒè®ºæ–‡

1. **PPO**: Schulman et al. "Proximal Policy Optimization Algorithms" - [arXiv:1707.06347](https://arxiv.org/abs/1707.06347)
2. **GAE**: Schulman et al. "High-Dimensional Continuous Control Using Generalized Advantage Estimation" - [arXiv:1506.02438](https://arxiv.org/abs/1506.02438)
3. **Boids**: Reynolds, C. W. "Flocks, Herds and Schools: A Distributed Behavioral Model"

### å¼€æºé¡¹ç›®

- [OpenAI Gym](https://gym.openai.com/) - ç¯å¢ƒæ¥å£æ ‡å‡†
- [PyTorch](https://pytorch.org/) - æ·±åº¦å­¦ä¹ æ¡†æ¶
- [onpolicy](https://github.com/marlbenchmark/onpolicy) - MAPPOå‚è€ƒå®ç°

---

<div align="center">

**å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸€ä¸ª â­ï¸ Starï¼**

Made with â¤ï¸ by High-Layer Controller Team

</div>
